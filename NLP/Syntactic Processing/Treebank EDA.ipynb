{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging - Lexicon and Rule Based Taggers\n",
    "\n",
    "Let's look at the two most basic tagging techniques - lexicon based (or unigram) and rule-based. \n",
    "\n",
    "In this guided exercise, you will explore the WSJ (wall street journal) POS-tagged corpus that comes with NLTK and build a lexicon and rule-based tagger using this corpus as the tarining data. \n",
    "\n",
    "This exercise is divided into the following sections:\n",
    "1. Reading and understanding the tagged dataset\n",
    "2. Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading and understanding the tagged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "wsj = list(nltk.corpus.treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('61', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('old', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('will', 'MD'),\n",
       "  ('join', 'VB'),\n",
       "  ('the', 'DT'),\n",
       "  ('board', 'NN'),\n",
       "  ('as', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('nonexecutive', 'JJ'),\n",
       "  ('director', 'NN'),\n",
       "  ('Nov.', 'NNP'),\n",
       "  ('29', 'CD'),\n",
       "  ('.', '.')],\n",
       " [('Mr.', 'NNP'),\n",
       "  ('Vinken', 'NNP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('chairman', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Elsevier', 'NNP'),\n",
       "  ('N.V.', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('the', 'DT'),\n",
       "  ('Dutch', 'NNP'),\n",
       "  ('publishing', 'VBG'),\n",
       "  ('group', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Rudolph', 'NNP'),\n",
       "  ('Agnew', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('55', 'CD'),\n",
       "  ('years', 'NNS'),\n",
       "  ('old', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('former', 'JJ'),\n",
       "  ('chairman', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('Consolidated', 'NNP'),\n",
       "  ('Gold', 'NNP'),\n",
       "  ('Fields', 'NNP'),\n",
       "  ('PLC', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('was', 'VBD'),\n",
       "  ('named', 'VBN'),\n",
       "  ('*-1', '-NONE-'),\n",
       "  ('a', 'DT'),\n",
       "  ('nonexecutive', 'JJ'),\n",
       "  ('director', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('this', 'DT'),\n",
       "  ('British', 'JJ'),\n",
       "  ('industrial', 'JJ'),\n",
       "  ('conglomerate', 'NN'),\n",
       "  ('.', '.')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples: Each sentence is a list of (word, pos) tuples\n",
    "wsj[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the list mentioned above, each element of the list is a sentence. Also, note that each sentence ends with a full stop '.' whose POS tag is also a '.'. Thus, the POS tag '.' demarcates the end of a sentence.\n",
    "\n",
    "Also, we do not need the corpus to be segmented into sentences, but can rather use a list of (word, tag) tuples. Let's convert the list into a (word, tag) tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the list of sents to a list of (word, pos tag) tuples\n",
    "tagged_words = [tup for sent in wsj for tup in sent]\n",
    "print(len(tagged_words))\n",
    "tagged_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a list of about 100676 (word, tag) tuples. Let's now do some exploratory analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Analysis\n",
    "\n",
    "Let's now conduct some basic exploratory analysis to understand the tagged corpus. To start with, let's ask some simple questions:\n",
    "1. How many unique tags are there in the corpus? \n",
    "2. Which is the most frequent tag in the corpus?\n",
    "3. Which tag is most commonly assigned to the following words:\n",
    "    - \"bank\"\n",
    "    - \"executive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cc9c481b3a2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# you can use the set() function on the list of tags to get a unique set of tags,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# and compute its length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0m____\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0munique_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '____' is not defined"
     ]
    }
   ],
   "source": [
    "# question 1: Find the number of unique POS tags in the corpus\n",
    "# you can use the set() function on the list of tags to get a unique set of tags, \n",
    "# and compute its length\n",
    "tags =  ____\n",
    "unique_tags = ____\n",
    "len(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2: Which is the most frequent tag in the corpus\n",
    "# to count the frequency of elements in a list, the Counter() class from collections\n",
    "# module is very useful, as shown below\n",
    "\n",
    "from collections import \n",
    "tag_counts = ___\n",
    "tag_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most common tags can be seen using the most_common() method of Counter\n",
    "tag_counts.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, NN is the most common tag followed by IN, NNP, DT, -NONE- etc. You can read the exhaustive list of tags using the NLTK documentation as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# list of POS tags in NLTK\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3: Which tag is most commonly assigned to the word w. Get the tags list that appear for word w and then use the Counter()\n",
    "# Try w ='bank' \n",
    "bank = Counter([___ == 'w'])\n",
    "bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3: Which tag is most commonly assigned to the word w. Try 'executive' \n",
    "executive = Counter([___ == 'executive'])\n",
    "executive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory Analysis Contd.\n",
    "\n",
    "Until now, we were looking at the frequency of tags assigned to particular words, which is the basic idea used by lexicon or unigram taggers. Let's now try observing some rules which can potentially be used for POS tagging. \n",
    "\n",
    "To start with, let's see if the following questions reveal something useful:\n",
    "\n",
    "4. What fraction of words with the tag 'VBD' (verb, past tense) end with the letters 'ed'\n",
    "5. What fraction of words with the tag 'VBG' (verb, present participle/gerund) end with the letters 'ing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. how many words with the tag 'VBD' (verb, past tense) end with 'ed'\n",
    "# first get the all the words tagged as VBD\n",
    "past_tense_verbs = [___=='VBD']\n",
    "\n",
    "# subset the past tense verbs with words ending with 'ed'. (Try w.endswith('ed'))\n",
    "ed_verbs = [___ for ___ in  if ___]\n",
    "print(len(ed_verbs) / len(past_tense_verbs))\n",
    "ed_verbs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. how many words with the tag 'VBG' end with 'ing'\n",
    "participle_verbs = [___ =='VBG']\n",
    "ing_verbs = [___ for ___ in ___ if ___]\n",
    "print(len(ing_verbs) / len(participle_verbs))\n",
    "ing_verbs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Analysis Continued\n",
    "\n",
    "Let's now try observing some tag patterns using the fact the some tags are more likely to apper after certain other tags. For e.g. most nouns NN are usually followed by determiners DT (\"The/DT constitution/NN\"), adjectives JJ usually precede a noun NN (\" A large/JJ building/NN\"), etc. \n",
    "\n",
    "Try answering the following questions:\n",
    "1. What fraction of adjectives JJ are followed by a noun NN? \n",
    "2. What fraction of determiners DT are followed by a noun NN?\n",
    "3. What fraction of modals MD are followed by a verb VB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question: what fraction of adjectives JJ are followed by a noun NN\n",
    "\n",
    "# create a list of all tags (without the words)\n",
    "tags = [___]\n",
    "\n",
    "# create a list of JJ tags\n",
    "jj_tags = [___]\n",
    "\n",
    "# create a list of (JJ, NN) tags\n",
    "jj_nn_tags = [(___) for index, t in enumerate(tags) \n",
    "              if ___ and ___]\n",
    "\n",
    "print(len(jj_tags))\n",
    "print(len(jj_nn_tags))\n",
    "print(len(jj_nn_tags) / len(jj_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question: what fraction of determiners DT are followed by a noun NN\n",
    "dt_tags = [___]\n",
    "dt_nn_tags = [(___) for index, t in enumerate(tags) \n",
    "              if ___ and ___]\n",
    "\n",
    "print(len(dt_tags))\n",
    "print(len(dt_nn_tags))\n",
    "print(len(dt_nn_tags) / len(dt_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question: what fraction of modals MD are followed by a verb VB?\n",
    "md_tags = [___]\n",
    "md_vb_tags = [(___) for index, t in enumerate(tags) \n",
    "              if ___ and ___]\n",
    "\n",
    "print(len(md_tags))\n",
    "print(len(md_vb_tags))\n",
    "print(len(md_vb_tags) / len(md_tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
